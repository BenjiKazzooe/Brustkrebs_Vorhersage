# Brustkrebs-Diagnose mit Maschinellem Lernen

Dieses Projekt nutzt verschiedene Machine-Learning-Modelle zur Diagnose von Brustkrebs basierend auf dem **Breast Cancer Wisconsin (Diagnostic) Data Set**. Es werden **Logistische Regression, Support Vector Machine, Random Forest und K-Nearest Neighbors** verwendet, um die Klassifikationsleistung zu vergleichen.

## ğŸ“‚ Daten
Die Daten stammen aus dem Kaggle-Datensatz: [Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data).

- **Merkmale (Features):**
  - Dies sind verschiedene diagnostische Messwerte aus einer Zellkernanalyse, die dabei helfen, zwischen gutartigen (harmlosen) und bÃ¶sartigen (gefÃ¤hrlichen) Tumoren zu unterscheiden.
  - Wichtigste Merkmale laut Feature-Importance-Analyse:
    1. `area_worst` â€“ GrÃ¶ÃŸte gemessene ZellkernflÃ¤che.
    2. `radius_worst` â€“ GrÃ¶ÃŸter gemessener Radius des Zellkerns.
    3. `concave points_worst` â€“ Anzahl der konkaven (nach innen gewÃ¶lbten) Punkte des Zellkerns.
    4. `perimeter_worst` â€“ GrÃ¶ÃŸter gemessener Umfang des Zellkerns.
    5. `concave points_mean` â€“ Durchschnittliche Anzahl der konkaven Punkte.
  
  Diese Merkmale sind besonders wichtig, weil grÃ¶ÃŸere und unregelmÃ¤ÃŸig geformte Zellkerne oft ein Hinweis auf bÃ¶sartige Tumoren sind.

- **Zielvariable (Target):**
  - `diagnosis` (B = gutartig, M = bÃ¶sartig)

## ğŸ“Š Modellierung & Ergebnisse
Die Daten wurden in **80% Trainings- und 20% Testdaten** aufgeteilt und normalisiert. FÃ¼r Random Forest wurde eine **Grid Search** zur Optimierung der Hyperparameter durchgefÃ¼hrt.

### ğŸ” Confusion Matrices
Eine Confusion Matrix zeigt die Leistung eines Klassifikationsmodells, indem sie die richtigen und falschen Vorhersagen in einer Tabelle zusammenfasst.

- **True Positives (TP):** Richtig als bÃ¶sartig erkannt
- **False Positives (FP):** FÃ¤lschlicherweise als bÃ¶sartig erkannt
- **True Negatives (TN):** Richtig als gutartig erkannt
- **False Negatives (FN):** FÃ¤lschlicherweise als gutartig erkannt

**Logistische Regression:**
```
[[70  1]
 [ 2 41]]
```
- 70 gutartige FÃ¤lle richtig erkannt (TN)
- 1 gutartiger Fall fÃ¤lschlicherweise als bÃ¶sartig klassifiziert (FP)
- 2 bÃ¶sartige FÃ¤lle nicht erkannt (FN)
- 41 bÃ¶sartige FÃ¤lle richtig erkannt (TP)

**Support Vector Machine:**
```
[[71  0]
 [ 2 41]]
```
- Perfekte Klassifikation der gutartigen FÃ¤lle (71 TN, 0 FP)
- 2 bÃ¶sartige FÃ¤lle wurden nicht erkannt (FN)
- 41 bÃ¶sartige FÃ¤lle korrekt erkannt (TP)

**Random Forest:**
```
[[70  1]
 [ 3 40]]
```
- 70 gutartige FÃ¤lle richtig erkannt (TN)
- 1 gutartiger Fall fÃ¤lschlicherweise als bÃ¶sartig klassifiziert (FP)
- 3 bÃ¶sartige FÃ¤lle nicht erkannt (FN)
- 40 bÃ¶sartige FÃ¤lle richtig erkannt (TP)

**K-Nearest Neighbors:**
```
[[68  3]
 [ 3 40]]
```
- 68 gutartige FÃ¤lle richtig erkannt (TN)
- 3 gutartige FÃ¤lle fÃ¤lschlicherweise als bÃ¶sartig klassifiziert (FP)
- 3 bÃ¶sartige FÃ¤lle nicht erkannt (FN)
- 40 bÃ¶sartige FÃ¤lle richtig erkannt (TP)

### ğŸ“ˆ Modellevaluation
Die Leistung der Modelle wurde anhand verschiedener Metriken bewertet:

- **Train Accuracy (Trainingsgenauigkeit):** Gibt an, wie gut das Modell auf den Trainingsdaten funktioniert.
- **Test Accuracy (Testgenauigkeit):** Zeigt, wie gut das Modell auf neuen (unbekannten) Daten arbeitet.
- **Precision (PrÃ¤zision):** Wie viele der vorhergesagten bÃ¶sartigen Tumore tatsÃ¤chlich bÃ¶sartig sind.
- **Recall (Empfindlichkeit):** Wie viele der tatsÃ¤chlichen bÃ¶sartigen Tumore richtig erkannt wurden.
- **F1 Score:** Eine Kombination aus PrÃ¤zision und Recall â€“ ein guter Indikator fÃ¼r das Gleichgewicht zwischen den beiden.
- **AUC-ROC:** Zeigt, wie gut das Modell zwischen gutartigen und bÃ¶sartigen Tumoren unterscheiden kann.

| Model                  | Train Accuracy | Test Accuracy | Precision | Recall | F1 Score | AUC-ROC |
|------------------------|---------------|--------------|-----------|--------|----------|---------|
| Logistic Regression    | 0.987         | 0.974        | 0.976     | 0.953  | 0.965    | 0.997   |
| Support Vector Machine| 0.989         | 0.982        | 1.000     | 0.953  | 0.976    | 0.997   |
| Random Forest         | 1.000         | 0.965        | 0.976     | 0.930  | 0.952    | 0.997   |
| K-Nearest Neighbors   | 0.982         | 0.947        | 0.930     | 0.930  | 0.930    | 0.981   |

## ğŸ“Œ Nutzung
1. **Installiere AbhÃ¤ngigkeiten:**
   ```bash
   pip install -r requirements.txt
   ```
2. **FÃ¼hre das Skript aus:**
   ```bash
   python breast_cancer_classification.py
   ```

## ğŸ›  Technologien
- **Python (3.x)**
- `pandas`, `numpy`, `scikit-learn`
- `GridSearchCV` zur Hyperparameter-Optimierung

## ğŸ“œ Fazit
Die **Support Vector Machine (SVM)** erzielte die hÃ¶chste Testgenauigkeit (98.2%) mit einer perfekten PrÃ¤zision (1.0). Auch die anderen Modelle lieferten starke Ergebnisse, insbesondere **Random Forest**, das mit AUC-ROC 0.997 gut abschnitt.

---
ğŸ“Œ **Autor:** Sir MÃ¶lli

